{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "\n",
    "\n",
    "def open_gff3_files(path:str= '') -> List[List[str]]:\n",
    "    '''\n",
    "    Opens and reads a GFF3 file and returns its contents as a list of lists.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    path: str\n",
    "        The path to the GFF3 file.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    List[List[str]]\n",
    "        A list of lists containing the contents of the GFF3 file.\n",
    "    '''\n",
    "    with open(path, 'r') as infile:\n",
    "        LINES = []\n",
    "        for line in infile:\n",
    "            LINES.append(line[:].split('\\t'))\n",
    "        LINES = LINES[1:]\n",
    "    \n",
    "    return LINES\n",
    "\n",
    "\n",
    "\n",
    "def tidy_up_gff(lst_of_gff:list) -> list:\n",
    "    \"\"\"\n",
    "    This function takes a list of GFF lines and returns a list of dictionaries,\n",
    "    with each dictionary containing information on the signal peptides in the GFF file.\n",
    "    \n",
    "    Parameters:\n",
    "    lst_of_gff (list): A list of GFF lines.\n",
    "    \n",
    "    Returns:\n",
    "    list_of_peptides (list): A list of dictionaries, with each dictionary containing information on the signal peptides in the GFF file.\n",
    "    \"\"\"\n",
    "    signal_peptides = {}\n",
    "    list_of_peptides = []\n",
    "\n",
    "    for peptide in lst_of_gff:\n",
    "        signal_peptides['gene'] = peptide[0][:19]\n",
    "        signal_peptides['start_pos'] = int(peptide[3])-1\n",
    "        signal_peptides['end_pos']= int(peptide[4])+1\n",
    "        signal_peptides['signal_peptide_likelyhood']= peptide[5]\n",
    "        list_of_peptides.append(signal_peptides)\n",
    "        signal_peptides = {'gene':'', 'start_pos':'', 'end_pos':'','signal_peptide_likelyhood': '' }\n",
    "\n",
    "    return list_of_peptides\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dict_of_signal_peptides(path: str = '') -> List[Dict[str, Union[str, int]]]:\n",
    "    \"\"\"\n",
    "    Given a path to a GFF3 file, returns a list of dictionaries with information on signal peptides.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the GFF3 file. Default is an empty string.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries where each dictionary contains the following keys:\n",
    "            - 'gene' (str): Gene name of the signal peptide.\n",
    "            - 'start_pos' (int): Start position of the signal peptide in the protein sequence.\n",
    "            - 'end_pos' (int): End position of the signal peptide in the protein sequence.\n",
    "            - 'signal_peptide_likelyhood' (str): The likelihood of the sequence being a signal peptide.\n",
    "    \"\"\"\n",
    "    gff = open_gff3_files(path)\n",
    "    dict_of_signal_peptides = tidy_up_gff(gff)\n",
    "    return dict_of_signal_peptides\n",
    "\n",
    "\n",
    "def read_gff_to_pd(path:str= '') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads a GFF3 file and returns a pandas DataFrame with columns 'gene', 'start_pos', 'end_pos', \n",
    "    and 'signal_peptide_likelyhood'.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : str\n",
    "        The path to the GFF3 file.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    df : pandas.DataFrame\n",
    "        A DataFrame with columns 'gene', 'start_pos', 'end_pos', and 'signal_peptide_likelyhood'.\n",
    "    \"\"\"\n",
    "    \n",
    "    gff = open_gff3_files(path)\n",
    "    dict_of_signal_peptides = tidy_up_gff(gff)\n",
    "    df = pd.DataFrame.from_records(dict_of_signal_peptides)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def get_signal_peptides_cross_ref_with_genome(list_of_peptides: List[dict], all_proteins: List[SeqRecord]) -> List[SeqRecord]:\n",
    "    \"\"\"\n",
    "    Extracts the protein sequence that corresponds to each predicted signal peptide sequence from the input list\n",
    "    of peptides and matches the signal peptide to its corresponding protein sequence in the input list of \n",
    "    protein sequences.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_peptides : list\n",
    "        A list of dictionaries containing information about predicted signal peptide sequences, including gene name, \n",
    "        start and end positions, and the signal peptide likelihood score.\n",
    "    all_proteins : list\n",
    "        A list of SeqRecord objects containing protein sequences.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of SeqRecord objects that correspond to the input predicted signal peptide sequences, including \n",
    "        protein sequence, ID, name, and a description indicating that the sequence corresponds to a predicted \n",
    "        signal peptide.\n",
    "    \"\"\"\n",
    "    signal_peptide_seqs = []\n",
    "\n",
    "    for signal_peptide in list_of_peptides:\n",
    "        for seqrecord in all_proteins:\n",
    "            if signal_peptide['gene'] in seqrecord.id:             \n",
    "                seq = SeqRecord(\n",
    "                    Seq(seqrecord.seq[signal_peptide['start_pos']:signal_peptide['end_pos']]), \n",
    "                    id=seqrecord.id,\n",
    "                    name=seqrecord.name,\n",
    "                    description=\"signal_peptide predicted by signalP\")\n",
    "\n",
    "                signal_peptide_seqs.append(seq)\n",
    "\n",
    "    return signal_peptide_seqs\n",
    "\n",
    "\n",
    "def add_dunder_tail(peptide:str , max_lenght:int=22 ): \n",
    "    '''Adds a tail if a peptide is shorter than the specified max_len.\n",
    "    '''\n",
    "    if len(peptide) < max_lenght: \n",
    "        difference = max_lenght - len(peptide)\n",
    "        sequence = peptide + ('-'*difference)\n",
    "    else: \n",
    "        sequence = peptide\n",
    "        \n",
    "    return sequence     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa1 = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "len(aa1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sp = 'MMVAWWSLFLYGLQVAAPAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teemi.design.combinatorial_design import get_combinatorial_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['M'],\n",
       " ['M'],\n",
       " ['V'],\n",
       " ['A'],\n",
       " ['W'],\n",
       " ['W'],\n",
       " ['S'],\n",
       " ['L'],\n",
       " ['F'],\n",
       " ['L'],\n",
       " ['Y'],\n",
       " ['G'],\n",
       " ['L'],\n",
       " ['Q'],\n",
       " ['V'],\n",
       " ['A'],\n",
       " ['A'],\n",
       " ['P'],\n",
       " ['A'],\n",
       " ['L']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sp = [list(seq) for seq in top_sp]\n",
    "list_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['M'],\n",
       " ['M'],\n",
       " ['V'],\n",
       " ['A'],\n",
       " ['W'],\n",
       " ['W'],\n",
       " ['S'],\n",
       " ['L'],\n",
       " ['F'],\n",
       " ['L'],\n",
       " ['Y'],\n",
       " ['G'],\n",
       " ['L'],\n",
       " ['Q'],\n",
       " ['V'],\n",
       " ['A'],\n",
       " ['A'],\n",
       " ['A',\n",
       "  'C',\n",
       "  'D',\n",
       "  'E',\n",
       "  'F',\n",
       "  'G',\n",
       "  'H',\n",
       "  'I',\n",
       "  'K',\n",
       "  'L',\n",
       "  'M',\n",
       "  'N',\n",
       "  'P',\n",
       "  'Q',\n",
       "  'R',\n",
       "  'S',\n",
       "  'T',\n",
       "  'V',\n",
       "  'W',\n",
       "  'Y'],\n",
       " ['A',\n",
       "  'C',\n",
       "  'D',\n",
       "  'E',\n",
       "  'F',\n",
       "  'G',\n",
       "  'H',\n",
       "  'I',\n",
       "  'K',\n",
       "  'L',\n",
       "  'M',\n",
       "  'N',\n",
       "  'P',\n",
       "  'Q',\n",
       "  'R',\n",
       "  'S',\n",
       "  'T',\n",
       "  'V',\n",
       "  'W',\n",
       "  'Y'],\n",
       " ['A',\n",
       "  'C',\n",
       "  'D',\n",
       "  'E',\n",
       "  'F',\n",
       "  'G',\n",
       "  'H',\n",
       "  'I',\n",
       "  'K',\n",
       "  'L',\n",
       "  'M',\n",
       "  'N',\n",
       "  'P',\n",
       "  'Q',\n",
       "  'R',\n",
       "  'S',\n",
       "  'T',\n",
       "  'V',\n",
       "  'W',\n",
       "  'Y']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sp[-3] = aa1\n",
    "list_sp[-2] = aa1\n",
    "list_sp[-1] = aa1\n",
    "list_sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_combinations = get_combinatorial_list(list_sp)\n",
    "len(all_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combinations_as_str = []\n",
    "aa_seq = ''\n",
    "for sp in all_combinations: \n",
    "    for seq in sp: \n",
    "        aa_seq += seq\n",
    "    \n",
    "    all_combinations_as_str.append(aa_seq)\n",
    "    aa_seq = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_combinations_as_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSEDVIKEFMRFKVRMEGSVNGHEFEIEGEGEGRPYEGTQTAKLKVTKGGPLPFAWDILSPQFQYGSKAYVKHPADIPDYLKLSFPEGFKWERVMNFEDGGVVTVTQDSSLQDGEFIYKVKLRGTNFPSDGPVMQKKTMGWEASTERMYPEDGALKGEIKMRLKLKDGGHYDAEVKTTYMAKKPVQLPGAYKTDIKLDITSHNEDYTIVEQYERAEGRHSTGAHHHHHH*\n"
     ]
    }
   ],
   "source": [
    "RFP = Seq('GCCTCCTCCGAGGACGTCATCAAGGAGTTCATGCGCTTCAAGGTGCGCATGGAGGGCTCCGTGAACGGCCACGAGTTCGAGATCGAGGGCGAGGGCGAGGGCCGCCCCTACGAGGGCACCCAGACCGCCAAGCTGAAGGTGACCAAGGGCGGCCCCCTGCCCTTCGCCTGGGACATCCTGTCCCCTCAGTTCCAGTACGGCTCCAAGGCCTACGTGAAGCACCCCGCCGACATCCCCGACTACTTGAAGCTGTCCTTCCCCGAGGGCTTCAAGTGGGAGCGCGTGATGAACTTCGAGGACGGCGGCGTGGTGACCGTGACCCAGGACTCCTCCCTGCAGGACGGCGAGTTCATCTACAAGGTGAAGCTGCGCGGCACCAACTTCCCCTCCGACGGCCCCGTAATGCAGAAGAAGACCATGGGCTGGGAGGCCTCCACCGAGCGGATGTACCCCGAGGACGGCGCCCTGAAGGGCGAGATCAAGATGAGGCTGAAGCTGAAGGACGGCGGCCACTACGACGCCGAGGTCAAGACCACCTACATGGCCAAGAAGCCCGTGCAGCTGCCCGGCGCCTACAAGACCGACATCAAGCTGGACATCACCTCCCACAACGAGGACTACACCATCGTGGAACAGTACGAGCGCGCCGAGGGCCGCCACTCCACCGGCGCCCATCATCATCATCATCATTAA')\n",
    "RFP = RFP.translate()\n",
    "print(RFP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_sp_combinations = []\n",
    "for i in range(len(all_combinations_as_str)): \n",
    "    sp = SeqRecord(all_combinations_as_str[i]) + RFP\n",
    "    sp.description, sp.name, sp.id  = \"\" , i, str(i)\n",
    "    \n",
    "    \n",
    "    list_of_all_sp_combinations.append(sp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_all_sp_combinations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition1 = list_of_all_sp_combinations[:5000]\n",
    "partition2 = list_of_all_sp_combinations[5000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/lucaslevassor/projects/Signal_peptide_project/data/13_all_sp_combinations_with_last_three_aa_mutated/first_partition.fasta\", \"w\") as output_handle:\n",
    "    SeqIO.write(partition1, output_handle, \"fasta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/lucaslevassor/projects/Signal_peptide_project/data/13_all_sp_combinations_with_last_three_aa_mutated/second_partition.fasta\", \"w\") as output_handle:\n",
    "    SeqIO.write(partition2, output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = read_gff_to_pd('/Users/lucaslevassor/projects/Signal_peptide_project/data/13_all_sp_combinations_with_last_three_aa_mutated/first_partition.gff3')\n",
    "second = read_gff_to_pd('/Users/lucaslevassor/projects/Signal_peptide_project/data/13_all_sp_combinations_with_last_three_aa_mutated/second_partition.gff3')\n",
    "\n",
    "all_sps = pd.concat([first, second])\n",
    "all_sps.to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, then most of the synthetic signal peptides predicted to be signal peptides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of all 8000 combinations, the number of predicted peptides are : 7338\n",
      "This is 91.725%\n"
     ]
    }
   ],
   "source": [
    "print(f'Out of all {len(all_combinations)} combinations, the number of predicted peptides are : {len(all_sps)}')\n",
    "print(f'This is {len(all_sps)/len(all_combinations)*100}% of the solution space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "constrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
