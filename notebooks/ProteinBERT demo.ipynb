{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The examples in this notebook use a set of nine benchmarks described in our publication.\n",
    "# These benchmarks can be downloaded via FTP from: ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks\n",
    "# Download the benchmarks into a directory on your machine and set the following variable to the path of that directory.\n",
    "BENCHMARKS_DIR = '../data/07_protein_benchmarks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'protein_bert'...\n",
      "remote: Enumerating objects: 206, done.\u001b[K\n",
      "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
      "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
      "remote: Total 206 (delta 52), reused 66 (delta 40), pack-reused 121\u001b[K\n",
      "Receiving objects: 100% (206/206), 23.43 MiB | 7.95 MiB/s, done.\n",
      "Resolving deltas: 100% (93/93), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/nadavbra/protein_bert.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this script for a mac with M1 chip follow this https://deeplabcut.github.io/DeepLabCut/docs/recipes/installTips.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#conda activate DEEPLABCUT_M1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the model for the signal peptide benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow-cpu import keras \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 64, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: Python version mismatch: module was compiled for Python 3.7, but the interpreter version is incompatible: 3.9.16 (main, Mar  8 2023, 04:29:44) \n[Clang 14.0.6 ].\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py:64\u001b[0m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=63'>64</a>\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pywrap_tensorflow_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=64'>65</a>\u001b[0m \u001b[39m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=65'>66</a>\u001b[0m \u001b[39m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=66'>67</a>\u001b[0m \u001b[39m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=67'>68</a>\u001b[0m \u001b[39m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=68'>69</a>\u001b[0m \n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=69'>70</a>\u001b[0m \u001b[39m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Python version mismatch: module was compiled for Python 3.7, but the interpreter version is incompatible: 3.9.16 (main, Mar  8 2023, 04:29:44) \n[Clang 14.0.6 ].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/__init__.py:41\u001b[0m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/__init__.py?line=37'>38</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msix\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_six\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/__init__.py?line=38'>39</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/__init__.py?line=40'>41</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/__init__.py?line=41'>42</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/__init__.py?line=43'>44</a>\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py:39\u001b[0m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=30'>31</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtraceback\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=32'>33</a>\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=33'>34</a>\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=34'>35</a>\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=35'>36</a>\u001b[0m \n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=36'>37</a>\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=37'>38</a>\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=38'>39</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=40'>41</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=42'>43</a>\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=43'>44</a>\u001b[0m \n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=44'>45</a>\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py:83\u001b[0m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=77'>78</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=78'>79</a>\u001b[0m   msg \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[39m\\n\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=79'>80</a>\u001b[0m \u001b[39mSee https://www.tensorflow.org/install/errors\u001b[39m\u001b[39m\\n\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=80'>81</a>\u001b[0m \u001b[39mfor some common reasons and solutions.  Include the entire stack trace\u001b[39m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=81'>82</a>\u001b[0m \u001b[39mabove this error message when asking for help.\u001b[39m\u001b[39m\"\"\"\u001b[39m \u001b[39m%\u001b[39m traceback\u001b[39m.\u001b[39mformat_exc()\n\u001b[0;32m---> <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=82'>83</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 64, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: Python version mismatch: module was compiled for Python 3.7, but the interpreter version is incompatible: 3.9.16 (main, Mar  8 2023, 04:29:44) \n[Clang 14.0.6 ].\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 62, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: Python version mismatch: module was compiled for Python 3.7, but the interpreter version is incompatible: 3.9.16 (main, Mar  8 2023, 04:29:44) \n[Clang 14.0.6 ].\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py:62\u001b[0m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=59'>60</a>\u001b[0m   ModuleNotFoundError = ImportError\n\u001b[0;32m---> <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=61'>62</a>\u001b[0m # pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=62'>63</a>\u001b[0m try:\n",
      "\u001b[0;31mImportError\u001b[0m: Python version mismatch: module was compiled for Python 3.7, but the interpreter version is incompatible: 3.9.16 (main, Mar  8 2023, 04:29:44) \n[Clang 14.0.6 ].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mproteinbert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mproteinbert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv_and_global_attention_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_model_with_hidden_layers_as_outputs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/proteinbert/__init__.py:3\u001b[0m\n\u001b[1;32m      <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/proteinbert/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mshared_utils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m log\n\u001b[1;32m      <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/proteinbert/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtokenization\u001b[39;00m \u001b[39mimport\u001b[39;00m ADDED_TOKENS_PER_SEQ\n\u001b[0;32m----> <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/proteinbert/__init__.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodel_generation\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelGenerator, PretrainingModelGenerator, FinetuningModelGenerator, InputEncoder, load_pretrained_model_from_dump, tokenize_seqs\n\u001b[1;32m      <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/proteinbert/__init__.py?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexisting_model_loading\u001b[39;00m \u001b[39mimport\u001b[39;00m load_pretrained_model\n\u001b[1;32m      <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/proteinbert/__init__.py?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfinetuning\u001b[39;00m \u001b[39mimport\u001b[39;00m OutputType, OutputSpec, finetune, evaluate_by_len\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/proteinbert/model_generation.py:6\u001b[0m\n\u001b[1;32m      <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/proteinbert/model_generation.py?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m      <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/proteinbert/model_generation.py?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/proteinbert/model_generation.py?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[1;32m      <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/proteinbert/model_generation.py?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mshared_utils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m log\n\u001b[1;32m      <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/proteinbert/model_generation.py?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtokenization\u001b[39;00m \u001b[39mimport\u001b[39;00m additional_token_to_index, n_tokens, tokenize_seq\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/__init__.py:37\u001b[0m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/__init__.py?line=34'>35</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_logging\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/__init__.py?line=35'>36</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_os\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/__init__.py?line=36'>37</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msite\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_site\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/__init__.py?line=37'>38</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msix\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_six\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/__init__.py?line=38'>39</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py:36\u001b[0m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=29'>30</a>\u001b[0m import sys\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=30'>31</a>\u001b[0m import traceback\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=32'>33</a>\u001b[0m # We aim to keep this file minimal and ideally remove completely.\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=33'>34</a>\u001b[0m # If you are adding a new file with @tf_export decorators,\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=34'>35</a>\u001b[0m # import it in modules_with_exports.py instead.\n\u001b[0;32m---> <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=35'>36</a>\u001b[0m \n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=36'>37</a>\u001b[0m # go/tf-wildcard-import\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=37'>38</a>\u001b[0m # pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=38'>39</a>\u001b[0m from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/__init__.py?line=40'>41</a>\u001b[0m from tensorflow.python.eager import context\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py:77\u001b[0m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=74'>75</a>\u001b[0m     pywrap_dlopen_global_flags\u001b[39m.\u001b[39mreset_dlopen_flags()\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=75'>76</a>\u001b[0m   \u001b[39melif\u001b[39;00m _can_set_rtld_local:\n\u001b[0;32m---> <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=76'>77</a>\u001b[0m     sys\u001b[39m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=77'>78</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=78'>79</a>\u001b[0m   msg \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[39m\\n\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=79'>80</a>\u001b[0m \u001b[39mSee https://www.tensorflow.org/install/errors\u001b[39m\u001b[39m\\n\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=80'>81</a>\u001b[0m \u001b[39mfor some common reasons and solutions.  Include the entire stack trace\u001b[39m\n\u001b[1;32m     <a href='file:///Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py?line=81'>82</a>\u001b[0m \u001b[39mabove this error message when asking for help.\u001b[39m\u001b[39m\"\"\"\u001b[39m \u001b[39m%\u001b[39m traceback\u001b[39m.\u001b[39mformat_exc()\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/Users/lucaslevassor/opt/anaconda3/envs/DEEPLABCUT_M1/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 62, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: Python version mismatch: module was compiled for Python 3.7, but the interpreter version is incompatible: 3.9.16 (main, Mar  8 2023, 04:29:44) \n[Clang 14.0.6 ].\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "BENCHMARK_NAME = 'signalP_binary'\n",
    "\n",
    "# A local (non-global) binary output\n",
    "OUTPUT_TYPE = OutputType(False, 'binary')\n",
    "UNIQUE_LABELS = [0, 1]\n",
    "OUTPUT_SPEC = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)\n",
    "\n",
    "\n",
    "# Loading the dataset\n",
    "\n",
    "train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.train.csv' % BENCHMARK_NAME)\n",
    "train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "train_set, valid_set = train_test_split(train_set, stratify = train_set['label'], test_size = 0.1, random_state = 0)\n",
    "\n",
    "test_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.test.csv' % BENCHMARK_NAME)\n",
    "test_set = pd.read_csv(test_set_file_path).dropna().drop_duplicates()\n",
    "\n",
    "print(f'{len(train_set)} training set records, {len(valid_set)} validation set records, {len(test_set)} test set records.')\n",
    "\n",
    "\n",
    "# Loading the pre-trained model and fine-tuning it on the loaded dataset\n",
    "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "\n",
    "# get_model_with_hidden_layers_as_outputs gives the model output access to the hidden layers (on top of the output)\n",
    "model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function = \\\n",
    "        get_model_with_hidden_layers_as_outputs, dropout_rate = 0.5)\n",
    "\n",
    "training_callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(patience = 1, factor = 0.25, min_lr = 1e-05, verbose = 1),\n",
    "    keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True),\n",
    "]\n",
    "\n",
    "finetune(model_generator, input_encoder, OUTPUT_SPEC, train_set['seq'], train_set['label'], valid_set['seq'], valid_set['label'], \\\n",
    "        seq_len = 512, batch_size = 32, max_epochs_per_stage = 40, lr = 1e-04, begin_with_frozen_pretrained_layers = True, \\\n",
    "        lr_with_frozen_pretrained_layers = 1e-02, n_final_epochs = 1, final_seq_len = 1024, final_lr = 1e-05, callbacks = training_callbacks)\n",
    "\n",
    "\n",
    "# Evaluating the performance on the test-set\n",
    "\n",
    "results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, OUTPUT_SPEC, test_set['seq'], test_set['label'], \\\n",
    "        start_seq_len = 512, start_batch_size = 32)\n",
    "\n",
    "print('Test-set performance:')\n",
    "display(results)\n",
    "\n",
    "print('Confusion matrix:')\n",
    "display(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len, log\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
    "\n",
    "BENCHMARKS = [\n",
    "    # name, output_type\n",
    "    ('signalP_binary', OutputType(False, 'binary')),\n",
    "    ('fluorescence', OutputType(False, 'numeric')),\n",
    "    ('remote_homology', OutputType(False, 'categorical')),\n",
    "    ('stability', OutputType(False, 'numeric')),\n",
    "    ('scop', OutputType(False, 'categorical')),\n",
    "    ('secondary_structure', OutputType(True, 'categorical')),\n",
    "    ('disorder_secondary_structure', OutputType(True, 'binary')),\n",
    "    ('ProFET_NP_SP_Cleaved', OutputType(False, 'binary')),\n",
    "    ('PhosphositePTM', OutputType(True, 'binary')),\n",
    "]\n",
    "\n",
    "settings = {\n",
    "    'max_dataset_size': None,\n",
    "    'max_epochs_per_stage': 40,\n",
    "    'seq_len': 512,\n",
    "    'batch_size': 32,\n",
    "    'final_epoch_seq_len': 1024,\n",
    "    'initial_lr_with_frozen_pretrained_layers': 1e-02,\n",
    "    'initial_lr_with_all_layers': 1e-04,\n",
    "    'final_epoch_lr': 1e-05,\n",
    "    'dropout_rate': 0.5,\n",
    "    'training_callbacks': [\n",
    "        keras.callbacks.ReduceLROnPlateau(patience = 1, factor = 0.25, min_lr = 1e-05, verbose = 1),\n",
    "        keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True),\n",
    "    ],\n",
    "}\n",
    "\n",
    "####### Uncomment for debug mode\n",
    "# settings['max_dataset_size'] = 500\n",
    "# settings['max_epochs_per_stage'] = 1\n",
    "\n",
    "def run_benchmark(benchmark_name, pretraining_model_generator, input_encoder, pretraining_model_manipulation_function = None):\n",
    "    \n",
    "    log('========== %s ==========' % benchmark_name)  \n",
    "    \n",
    "    output_type = get_benchmark_output_type(benchmark_name)\n",
    "    log('Output type: %s' % output_type)\n",
    "    \n",
    "    train_set, valid_set, test_set = load_benchmark_dataset(benchmark_name)        \n",
    "    log(f'{len(train_set)} training set records, {len(valid_set)} validation set records, {len(test_set)} test set records.')\n",
    "    \n",
    "    if settings['max_dataset_size'] is not None:\n",
    "        log('Limiting the training, validation and test sets to %d records each.' % settings['max_dataset_size'])\n",
    "        train_set = train_set.sample(min(settings['max_dataset_size'], len(train_set)), random_state = 0)\n",
    "        valid_set = valid_set.sample(min(settings['max_dataset_size'], len(valid_set)), random_state = 0)\n",
    "        test_set = test_set.sample(min(settings['max_dataset_size'], len(test_set)), random_state = 0)\n",
    "    \n",
    "    if output_type.is_seq or output_type.is_categorical:\n",
    "        train_set['label'] = train_set['label'].astype(str)\n",
    "        valid_set['label'] = valid_set['label'].astype(str)\n",
    "        test_set['label'] = test_set['label'].astype(str)\n",
    "    else:\n",
    "        train_set['label'] = train_set['label'].astype(float)\n",
    "        valid_set['label'] = valid_set['label'].astype(float)\n",
    "        test_set['label'] = test_set['label'].astype(float)\n",
    "        \n",
    "    if output_type.is_categorical:\n",
    "        \n",
    "        if output_type.is_seq:\n",
    "            unique_labels = sorted(set.union(*train_set['label'].apply(set)) | set.union(*valid_set['label'].apply(set)) | \\\n",
    "                    set.union(*test_set['label'].apply(set)))\n",
    "        else:\n",
    "            unique_labels = sorted(set(train_set['label'].unique()) | set(valid_set['label'].unique()) | set(test_set['label'].unique()))\n",
    "            \n",
    "        log('%d unique lebels.' % len(unique_labels))\n",
    "    elif output_type.is_binary:\n",
    "        unique_labels = [0, 1]\n",
    "    else:\n",
    "        unique_labels = None\n",
    "        \n",
    "    output_spec = OutputSpec(output_type, unique_labels)\n",
    "    model_generator = FinetuningModelGenerator(pretraining_model_generator, output_spec, pretraining_model_manipulation_function = \\\n",
    "            pretraining_model_manipulation_function, dropout_rate = settings['dropout_rate'])\n",
    "    finetune(model_generator, input_encoder, output_spec, train_set['seq'], train_set['label'], valid_set['seq'], valid_set['label'], \\\n",
    "            seq_len = settings['seq_len'], batch_size = settings['batch_size'], max_epochs_per_stage = settings['max_epochs_per_stage'], \\\n",
    "            lr = settings['initial_lr_with_all_layers'], begin_with_frozen_pretrained_layers = True, lr_with_frozen_pretrained_layers = \\\n",
    "            settings['initial_lr_with_frozen_pretrained_layers'], n_final_epochs = 1, final_seq_len = settings['final_epoch_seq_len'], \\\n",
    "            final_lr = settings['final_epoch_lr'], callbacks = settings['training_callbacks'])\n",
    "    \n",
    "    for dataset_name, dataset in [('Training-set', train_set), ('Validation-set', valid_set), ('Test-set', test_set)]:\n",
    "        \n",
    "        log('*** %s performance: ***' % dataset_name)\n",
    "        results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, output_spec, dataset['seq'], dataset['label'], \\\n",
    "                start_seq_len = settings['seq_len'], start_batch_size = settings['batch_size'])\n",
    "    \n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "            display(results)\n",
    "        \n",
    "        if confusion_matrix is not None:\n",
    "            with pd.option_context('display.max_rows', 16, 'display.max_columns', 10):\n",
    "                log('Confusion matrix:')\n",
    "                display(confusion_matrix)\n",
    "                \n",
    "    return model_generator\n",
    "\n",
    "def load_benchmark_dataset(benchmark_name):\n",
    "    \n",
    "    train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.train.csv' % benchmark_name)\n",
    "    valid_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.valid.csv' % benchmark_name)\n",
    "    test_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.test.csv' % benchmark_name)\n",
    "    \n",
    "    train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "    test_set = pd.read_csv(test_set_file_path).dropna().drop_duplicates()\n",
    "          \n",
    "    if os.path.exists(valid_set_file_path):\n",
    "        valid_set = pd.read_csv(valid_set_file_path).dropna().drop_duplicates()\n",
    "    else:\n",
    "        log(f'Validation set {valid_set_file_path} missing. Splitting training set instead.')\n",
    "        train_set, valid_set = train_test_split(train_set, stratify = train_set['label'], test_size = 0.1, random_state = 0)\n",
    "    \n",
    "    return train_set, valid_set, test_set\n",
    "\n",
    "def get_benchmark_output_type(benchmark_name):\n",
    "    for name, output_type in BENCHMARKS:\n",
    "        if name == benchmark_name:\n",
    "            return output_type\n",
    "        \n",
    "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "\n",
    "for benchmark_name, _ in BENCHMARKS:\n",
    "    run_benchmark(benchmark_name, pretrained_model_generator, input_encoder, pretraining_model_manipulation_function = \\\n",
    "            get_model_with_hidden_layers_as_outputs)\n",
    "        \n",
    "log('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the attention layers\n",
    "\n",
    "You can run this only after you have fine-tuned the model on a benchmark (e.g. signal peptide) and obtained *model_generator*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BENCHMARK_DISPLAY_NAME = 'Signal peptide'\n",
    "\n",
    "TEST_SET_FILE_PATH = '/cs/phd/nadavb/my_public_ftp_site/protein_bert/protein_benchmarks/signalP_binary.train.csv'\n",
    "IDEAL_LEN = 80\n",
    "\n",
    "def calculate_attentions(model, input_encoder, seq, seq_len = None):\n",
    "    \n",
    "    from tensorflow.keras import backend as K\n",
    "    from proteinbert.tokenization import index_to_token\n",
    "    \n",
    "    if seq_len is None:\n",
    "        seq_len = len(seq) + 2\n",
    "    \n",
    "    X = input_encoder.encode_X([seq], seq_len)\n",
    "    (X_seq,), _ = X\n",
    "    seq_tokens = list(map(index_to_token.get, X_seq))\n",
    "\n",
    "    model_inputs = [layer.input for layer in model.layers if 'InputLayer' in str(type(layer))][::-1]\n",
    "    model_attentions = [layer.calculate_attention(layer.input) for layer in model.layers if 'GlobalAttention' in str(type(layer))]\n",
    "    invoke_model_attentions = K.function(model_inputs, model_attentions)\n",
    "    attention_values = invoke_model_attentions(X)\n",
    "    \n",
    "    attention_labels = []\n",
    "    merged_attention_values = []\n",
    "\n",
    "    for attention_layer_index, attention_layer_values in enumerate(attention_values):\n",
    "        for head_index, head_values in enumerate(attention_layer_values):\n",
    "            attention_labels.append('Attention %d - head %d' % (attention_layer_index + 1, head_index + 1))\n",
    "            merged_attention_values.append(head_values)\n",
    "\n",
    "    attention_values = np.array(merged_attention_values)\n",
    "    \n",
    "    return attention_values, seq_tokens, attention_labels\n",
    "\n",
    "def plot_attention(attention_values, seq_tokens, attention_labels, ax, cmap = 'Reds', vmin = 0, vmax = None, text_value_threshold = 0.1):\n",
    "\n",
    "    heatmap = ax.pcolor(attention_values.transpose(), cmap = cmap, vmin = vmin, vmax = vmax)\n",
    "\n",
    "    ax.set_xticks(np.arange(len(attention_labels)) + 0.5)\n",
    "    ax.set_xticklabels(attention_labels, rotation = 45, ha = 'right', fontsize = 12)\n",
    "    ax.set_yticks(np.arange(len(seq_tokens)) + 0.5)\n",
    "    ax.set_yticklabels(seq_tokens, fontsize = 12)\n",
    "\n",
    "    for i, row in enumerate(attention_values):\n",
    "        for j, value in enumerate(row):\n",
    "            if abs(value) >= text_value_threshold:\n",
    "                add_plus_sign = attention_values.min() < 0 and value > 0\n",
    "                plus_sign = '+' if add_plus_sign else ''\n",
    "                ax.text(i + 0.5, j + 0.5, plus_sign + '%d%%' % (100 * value), color = 'white', ha = 'center', va = 'center', \\\n",
    "                        fontsize = 9, fontweight = 'bold', fontstretch = 'condensed')\n",
    "                \n",
    "test_set = pd.read_csv(TEST_SET_FILE_PATH)\n",
    "chosen_index = ((test_set['seq'].str.len() - IDEAL_LEN).abs()).sort_values().index[0]\n",
    "seq = test_set.loc[chosen_index, 'seq']\n",
    "label = test_set.loc[chosen_index, 'label']\n",
    "                \n",
    "seq_len = len(seq) + 2\n",
    "\n",
    "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "model = pretrained_model_generator.create_model(seq_len)\n",
    "pretrained_attention_values, pretrained_seq_tokens, pretrained_attention_labels = calculate_attentions(model, input_encoder, seq, \\\n",
    "        seq_len = seq_len)\n",
    "\n",
    "model = model_generator.create_model(seq_len)\n",
    "finetuned_attention_values, finetuned_seq_tokens, finetuned_attention_labels = calculate_attentions(model, input_encoder, seq, \\\n",
    "        seq_len = seq_len)\n",
    "assert finetuned_seq_tokens == pretrained_seq_tokens\n",
    "assert finetuned_attention_labels == pretrained_attention_labels[:len(finetuned_attention_labels)]\n",
    "\n",
    "fig, axes = plt.subplots(ncols = 4, figsize = (20, 0.2 * seq_len), gridspec_kw = dict(width_ratios = [1, 5, 1, 5]))\n",
    "fig.subplots_adjust(wspace = 0.3)\n",
    "\n",
    "axes[0].barh(np.arange(seq_len), 100 * pretrained_attention_values.sum(axis = 0), color = '#EC7063')\n",
    "axes[0].set_ylim((-0.5, seq_len - 0.5))\n",
    "axes[0].set_yticks([])\n",
    "axes[0].invert_xaxis()\n",
    "axes[0].set_xlabel('Total atten. %', fontsize = 14)\n",
    "\n",
    "vmax = pretrained_attention_values.max()\n",
    "plot_attention(pretrained_attention_values, pretrained_seq_tokens, pretrained_attention_labels, axes[1], cmap = 'Reds', vmax = vmax, \\\n",
    "        text_value_threshold = 0.05)\n",
    "axes[1].set_title('Only pre-training', fontsize = 16)\n",
    "\n",
    "axes[2].barh(np.arange(seq_len), 100 * (finetuned_attention_values - pretrained_attention_values).sum(axis = 0), color = '#28B463')\n",
    "axes[2].set_ylim((-0.5, seq_len - 0.5))\n",
    "axes[2].set_yticks([])\n",
    "axes[2].invert_xaxis()\n",
    "axes[2].set_xlabel('Total atten. % diff', fontsize = 14)\n",
    "\n",
    "attention_diff = finetuned_attention_values - pretrained_attention_values[:len(finetuned_attention_labels), :]\n",
    "vmax = np.abs(attention_diff).max()\n",
    "plot_attention(attention_diff, finetuned_seq_tokens, finetuned_attention_labels, axes[3], cmap = 'PiYG', vmin = -vmax, vmax = vmax, \\\n",
    "        text_value_threshold = 0.03)\n",
    "axes[3].set_title('%s fine-tuning' % BENCHMARK_DISPLAY_NAME, fontsize = 16)\n",
    "\n",
    "print(seq, label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
